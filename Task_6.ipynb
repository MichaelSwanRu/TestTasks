{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружу библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph=pymorphy2.MorphAnalyzer()\n",
    "import numpy as np\n",
    "import datetime\n",
    "random_state = 17\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "import pickle as pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "# будем отображать графики прямо в jupyter'e\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import xmltodict\n",
    "from tqdm import tqdm\n",
    "import pickle as pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка текста и модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myPreprocessor(object):\n",
    "    \n",
    "    global _names,_surnames, _secondnames \n",
    "    def __init__(self, _names):\n",
    "\n",
    "        self._names = _names[0]\n",
    "        self._surnames = _names[1]\n",
    "        self._secondnames = _names[2]           \n",
    "\n",
    "    def preprocess1(self, colname, text):\n",
    "        if colname not in self._preprocess:\n",
    "            return text\n",
    "        func = self._preprocess[colname]\n",
    "        if isinstance(text, pd.Series):\n",
    "            return text.apply(func)\n",
    "        return func(text)\n",
    "\n",
    "    def preprocess(self, colname, text):\n",
    "        \n",
    "        global change_level_5\n",
    "        def change_level_5(text, level, template):\n",
    "            if text in level: return template\n",
    "            return text_proc_3(text)    \n",
    "    \n",
    "    \n",
    "        global replace_template\n",
    "        def replace_template(row, target, template):\n",
    "            row = row.split()\n",
    "            for i in range(len(row)):\n",
    "                if row[i].count(target) > 0:\n",
    "                    row[i] = template\n",
    "            row = text_proc_3(concat(row))\n",
    "            return row\n",
    "        \n",
    "        global text_proc_3\n",
    "        def text_proc_3(text):\n",
    "            if text != '':\n",
    "                text = re.sub(r\"\\s+\", \" \", text) # убрал лишние пробелы (\\s+ Любой пробельный символ 1 и более вхождений шаблона)\n",
    "                text = re.sub(r\"^\\s+\", \"\", text) #  уберу первые пробелы в начале строки\n",
    "                text = text.rstrip() #  уберу последний пробел в начале строки\n",
    "            return text\n",
    "        \n",
    "        global cat_from_template2\n",
    "        def cat_from_template2(text, level, template):\n",
    "            row = text.split(' ')\n",
    "            row = [change_level_5(x, level, template) for x in row]\n",
    "            row = text_proc_3(concat(row))\n",
    "            return row\n",
    "        \n",
    "        global cat_phrase\n",
    "        def cat_phrase(phrase, text):\n",
    "            if phrase in text:\n",
    "                nomer_phrase = text.find(phrase)\n",
    "                text = text[0:nomer_phrase:]\n",
    "            return text\n",
    "        \n",
    "        global collapse_ne_2\n",
    "        def collapse_ne_2(string):\n",
    "            if string != '':\n",
    "                string = string.split(' ')\n",
    "                for i in range(len(string)-1):\n",
    "                    if string[i] == 'не':\n",
    "                        string[i] = string[i]+'_'+string[i+1]\n",
    "                        string[i+1] = ''\n",
    "                string0 = string[0]\n",
    "                for i in range(1, len(string)):\n",
    "                    string0 = string0 + ' ' + string[i]\n",
    "                string = re.sub(r'\\s+', ' ', string0)\n",
    "            return string\n",
    "    \n",
    "        global compare   \n",
    "        def compare(a, b):\n",
    "            if a == b: return 1\n",
    "            if a != b: return 0\n",
    "        \n",
    "        global got_counter\n",
    "        def got_counter(per):\n",
    "            counter = Counter()\n",
    "            for i in range(len(per)):\n",
    "                word = per[i]\n",
    "                counter[word] += 1\n",
    "            return counter\n",
    "\n",
    "        global lemma     \n",
    "        def lemma(txt):\n",
    "            return morph.parse(txt)[0].normal_form\n",
    "        \n",
    "        global concat\n",
    "        def concat(vec):\n",
    "            return ' '.join(vec)\n",
    "    \n",
    "        global cat_from_template\n",
    "        def cat_from_template(template, text_string):\n",
    "            row = text_string.split()\n",
    "            row = [x for x in row if x not in template]\n",
    "            row = concat(row)\n",
    "            return row\n",
    "        \n",
    "        global mynewpreprocessing4\n",
    "        def mynewpreprocessing4(string, A = 3):\n",
    "            if string != '':\n",
    "                lev = ['\\n', '\\r', 'нестандартный','зно','подробное','описание','null','вопрос/проблема','информацию по',\n",
    "                       'инциденту','вы можете увидеть в протоколе','добрый','день', 'коллеги', 'в работу поступила заявка',\n",
    "                       'просим','помочь','спасибо', 'просьба','решении','ошибке','оказать','содействие','проблемы','по заявке',\n",
    "                       'имеется','следующая','проблема','помогите','решить проблему','разбудить','прошу решить вопрос',\n",
    "                       'как можно','очень','срочно','быстрее','табельный номер','здравствуйте',\n",
    "                       ';', '=', '–', '*', '%', '<', '>', '\"', '-', '«', '»', '(', ')']        \n",
    "                string = replace_template(string, 'Cброс', 'Сброс')\n",
    "                string = string.lower()\n",
    "                string = string.replace('ё', 'е')\n",
    "                string = replace_template(string, '@', 'почтовый_адрес')\n",
    "                string = string.replace(':', '.')\n",
    "                string = string.replace('!', '.')\n",
    "                string = string.replace(',', '.')\n",
    "                string = string.replace('.', ' . ')\n",
    "                string = cat_from_template2(string, lev, ' ')\n",
    "                string = cat_phrase('с уважением', string)\n",
    "                string = string.replace(' . ', ' ')\n",
    "                string = string.replace('№', '')\n",
    "                string = string.replace('sd', '')\n",
    "                string = string.replace('im', '')\n",
    "                string = string.replace('\\\\', ' ')\n",
    "                string = string.replace(' .', '. ')\n",
    "                string = string.replace('•', '.')\n",
    "                string = string.replace('.', ' ')\n",
    "                string = re.sub('[^а-яА-Яa-zA-Z]', ' ', string) # заменил на пробел не буквы\n",
    "                string = text_proc_3(string) # убрал лишние пробелы    \n",
    "                string = text_proc_3(concat(list(  [lemma(j) for j in string.split() ] ) ))\n",
    "                string = collapse_ne_2(string)\n",
    "            \n",
    "                # вытащим все англ слова и удалим лишние\n",
    "                all_uniq = []\n",
    "                row = [text_proc_3(re.sub('[^a-zA-Z]', ' ', string))]\n",
    "                for j in row:\n",
    "                    if j != '':\n",
    "                        all_uniq.append(j)\n",
    "            \n",
    "                counter = got_counter(all_uniq)\n",
    "                if counter != Counter():\n",
    "                    res_df = pd.DataFrame.from_dict(counter, orient='index').reset_index().rename(columns={'index':'event', 0:'count'})\n",
    "                    res_df = res_df.sort_values(by=['count'], ascending=False).reset_index(drop=True)       \n",
    "                    levelB = [x for x in res_df[res_df['count'] < A]['event']]\n",
    "                    levelB.sort()\n",
    "                    string = text_proc_3(cat_from_template(levelB, string))\n",
    "                    \n",
    "                # вытащим все RUS слова и удалим лишние\n",
    "                all_uniq = []\n",
    "                row = [text_proc_3(re.sub('[^а-яА-Я_]', ' ', string))]\n",
    "                for j in row:\n",
    "                    if j != '':\n",
    "                        all_uniq.append(j)\n",
    "                \n",
    "                counter = got_counter(all_uniq)\n",
    "                if counter != Counter():\n",
    "                    res_df = pd.DataFrame.from_dict(counter, orient='index').reset_index().rename(columns={'index':'event', 0:'count'})\n",
    "                    res_df = res_df.sort_values(by=['count'], ascending=False).reset_index(drop=True) \n",
    "                    levelB = [x for x in res_df[res_df['count'] < A]['event']]\n",
    "                    levelB.sort()\n",
    "                    string = text_proc_3(cat_from_template(levelB, string))\n",
    "                return string\n",
    "            return string\n",
    "    \n",
    "        global devide_keys_values_3\n",
    "        def devide_keys_values_3(wk, diction):\n",
    "            global df\n",
    "            if diction is not None:\n",
    "                if type(diction) == str: print ('str', diction);\n",
    "                if type(diction) != list and type(diction) != str:\n",
    "                    for key, value in diction.items():\n",
    "                        if type(value) == str: \n",
    "                            if len(wk) != 0:  w = wk + '-' + str(key)\n",
    "                            if len(wk) == 0:  w = str(key) \n",
    "                            df[w] = str(value)\n",
    "                        if type(value) == list:\n",
    "                            for i in range(len(value)):            \n",
    "                                if len(wk) != 0:  w = str(i) + wk + '-' + str(key)  #str(diction.keys()[0])\n",
    "                                if len(wk) == 0:  w = str(i) + str(key)  #str(diction.keys()[0]) \n",
    "                                devide_keys_values_3( w, value[i])\n",
    "                        if type(value) != str and type(value) != list: \n",
    "                            if len(wk) != 0:  w = wk + '-' + str(key)\n",
    "                            if len(wk) == 0:  w = str(key) \n",
    "                            devide_keys_values_3( w, value)\n",
    "                if type(diction) == list:\n",
    "                    if len(wk) != 0:  w = wk + '-' + str(diction[0])\n",
    "                    if len(wk) == 0:  w = str(diction[0]) \n",
    "                    for i in diction:\n",
    "                        devide_keys_values_3( w, i)    \n",
    "    \n",
    "        global find_name_surname\n",
    "        def find_name_surname(row):\n",
    "            global _names, _surnames, _secondnames\n",
    "            rez = -1\n",
    "            st = ''\n",
    "            txt = ''\n",
    "            if len(row) == 3:\n",
    "                sec = row[2][-3:]\n",
    "                if sec == 'вна' or sec == 'вич' or sec == 'чна' or sec == 'ьич':\n",
    "                    if row[1] in self._names:\n",
    "                        if row[0] in self._surnames:\n",
    "                            txt = row[0] + ' ' + row[1] + ' ' + row[2]\n",
    "                            rez = 0; st = 'ОК'\n",
    "                            self._secondnames.append(row[2])\n",
    "                        else:\n",
    "                            txt = row[0] + ' ' + row[1] + ' ' + row[2]\n",
    "                            rez = 1; st = '+Ф'\n",
    "                            self._surnames.append(row[0])\n",
    "                            self._secondnames.append(row[2])\n",
    "                    if row[1] not in self._names:\n",
    "                        if row[0] in self._surnames: \n",
    "                            self._names.append(row[1])\n",
    "                            self._secondnames.append(row[2])\n",
    "                            rez = 2; st = '+И'\n",
    "                        else:\n",
    "                            if row[2][-4:] == 'овна':\n",
    "                                if row[2][:-4] in self._names:\n",
    "                                    self._names.append(row[1])\n",
    "                                    self._surnames.append(row[0])\n",
    "                                    self._secondnames.append(row[2])\n",
    "                                    rez = 3; st = '+ИФ'\n",
    "                                else:\n",
    "                                    self._names.append(row[1])\n",
    "                                    self._surnames.append(row[0])\n",
    "                                    self._secondnames.append(row[2])\n",
    "                                    rez = 4; st = '+ИФ-'\n",
    "                if sec != 'вна' and sec != 'вич' and sec != 'чна' and sec != 'ьич':\n",
    "                    if row[1][-3:] == 'вна' or row[1][-3:] == 'вич' or row[1][-3:] == 'чна':\n",
    "                        self._secondnames.append(row[1])\n",
    "                        if row[0] in self._names:\n",
    "                            txt = row[2] + ' ' + row[0] + ' ' + row[1]\n",
    "                            rez = 5; st = 'ИОФ-ФИО'\n",
    "                            self._surnames.append(row[2])                        \n",
    "            return txt, rez, st\n",
    "        \n",
    "        global preptext_en\n",
    "        def preptext_en(text):\n",
    "            text = text.replace('\\n', ' ').replace('\\r', ' ').replace(',', ' ').replace('>',' ' )\n",
    "            text = text.replace('ё', 'е')\n",
    "            text = re.sub('[^а-яА-Яa-zA-Z]', ' ', text) # заменил на пробел не буквы\n",
    "            text = text.lower()\n",
    "            \n",
    "            lev = ['нестандартный','зно','подробное','описание','null','вопрос/проблема','информацию по',\n",
    "               'инциденту','вы можете увидеть в протоколе','добрый','день', 'коллеги', 'в работу поступила заявка',\n",
    "               'просим','помочь','спасибо', 'просьба','решении','ошибке','оказать','содействие','проблемы','по заявке',\n",
    "               'имеется','следующая','проблема','помогите','решить проблему','разбудить','прошу решить вопрос',\n",
    "               'как можно','очень','срочно','быстрее','табельный номер','здравствуйте',\n",
    "               ';', '=', '–', '*', '%', '<', '>', '\"', '-', '«', '»', '(', ')'] \n",
    "            \n",
    "            text = cat_from_template2(text, lev, ' ')\n",
    "            \n",
    "            text = re.sub(r\"\\s+\", \" \", text) # убрал лишние пробелы (\\s+ Любой пробельный символ 1 и более вхождений шаблона)\n",
    "            text = re.sub(' \\w ', ' ', text) # Любая цифра или буква\n",
    "            text = re.sub(r\"^\\s+\", \"\", text) #  уберу первые пробелы в начале строки\n",
    "            text = text.rstrip() #  уберу последний пробел в начале строки\n",
    "            return text\n",
    "               \n",
    "        global mynewpreprocessing3\n",
    "        def mynewpreprocessing3(db, A = 3):\n",
    "            lev = ['\\n', '\\r', 'нестандартный','зно','подробное','описание','null','вопрос/проблема','информацию по',\n",
    "                   'инциденту','вы можете увидеть в протоколе','добрый','день', 'коллеги', 'в работу поступила заявка',\n",
    "                   'просим','помочь','спасибо', 'просьба','решении','ошибке','оказать','содействие','проблемы','по заявке',\n",
    "                   'имеется','следующая','проблема','помогите','решить проблему','разбудить','прошу решить вопрос',\n",
    "                   'как можно','очень','срочно','быстрее','табельный номер','здравствуйте',\n",
    "                   ';', '=', '–', '*', '%', '<', '>', '\"', '-', '«', '»', '(', ')']\n",
    "            db = [replace_template(x, 'Cброс', 'Сброс') for x in db]\n",
    "            db = [x.lower() for x in db]\n",
    "            db = [x.replace('ё', 'е') for x in db]\n",
    "            db = [replace_template(x, '@', 'почтовый_адрес') for x in db] # ЗАМЕНИЛ почтовый адрес на темплейт\n",
    "            db = [x.replace(':', '.') for x in db]\n",
    "            db = [x.replace('!', '.') for x in db]\n",
    "            db = [x.replace(',', '.') for x in db]\n",
    "            db = [x.replace('.', ' . ') for x in db]\n",
    "            db = [cat_from_template2(x, lev, ' ') for x in db]\n",
    "            db = [cat_phrase('с уважением', x) for x in db]\n",
    "            db = [x.replace(' . ', ' ') for x in db]\n",
    "            db = [x.replace('№', '') for x in db]\n",
    "            db = [x.replace('sd', '') for x in db]\n",
    "            db = [x.replace('im', '') for x in db]\n",
    "            db = [x.replace('\\\\', ' ') for x in db] \n",
    "            db = [x.replace(' .', '. ') for x in db]\n",
    "            db = [x.replace('•', '.') for x in db]\n",
    "            db = [x.replace('.', ' ') for x in db]\n",
    "            db = [re.sub('[^а-яА-Яa-zA-Z]', ' ', x)  for x in db] # заменил на пробел не буквы\n",
    "            db = [text_proc_3(x) for x in db] # убрал лишние пробелы    \n",
    "            db = [text_proc_3(concat(list(  [lemma(j) for j in x.split() ] ) )) for x in db]\n",
    "            db = [collapse_ne_2(x) for x in db]\n",
    "           \n",
    "            # вытащим все англ слова и удалим лишние\n",
    "            all_uniq = []\n",
    "            for i in (range(len(db))):\n",
    "                row = [text_proc_3(re.sub('[^a-zA-Z]', ' ', x)) for x in db[i].split(' ') if text_proc_3(x) != '']\n",
    "                for j in row:\n",
    "                    if j != '':\n",
    "                        all_uniq.append(j)\n",
    "            \n",
    "            counter = got_counter(all_uniq)\n",
    "            if counter != Counter():\n",
    "                res_df = pd.DataFrame.from_dict(counter, orient='index').reset_index().rename(columns={'index':'event', 0:'count'})\n",
    "                res_df = res_df.sort_values(by=['count'], ascending=False).reset_index(drop=True)       \n",
    "                levelB = [x for x in res_df[res_df['count'] < A]['event']]\n",
    "                levelB.sort()\n",
    "                db = [text_proc_3(cat_from_template(levelB, x)) for x in db]\n",
    "                \n",
    "            # вытащим все RUS слова и удалим лишние\n",
    "            all_uniq = []\n",
    "            for i in (range(len(db))):\n",
    "                row = [text_proc_3(re.sub('[^а-яА-Я_]', ' ', x)) for x in db[i].split(' ') if text_proc_3(x) != '']\n",
    "                for j in row:\n",
    "                    if j != '':\n",
    "                        all_uniq.append(j)\n",
    "            \n",
    "            counter = got_counter(all_uniq)\n",
    "            if counter != Counter():\n",
    "                res_df = pd.DataFrame.from_dict(counter, orient='index').reset_index().rename(columns={'index':'event', 0:'count'})\n",
    "                res_df = res_df.sort_values(by=['count'], ascending=False).reset_index(drop=True) \n",
    "                levelB = [x for x in res_df[res_df['count'] < A]['event']]\n",
    "                levelB.sort()\n",
    "                db = [text_proc_3(cat_from_template(levelB, x)) for x in db]\n",
    "                #db = [text_proc_3(cat_from_template(trash, x)) for x in tqdm(db)]\n",
    "            return db\n",
    "        \n",
    "        global change_nan\n",
    "        def change_nan(x):\n",
    "            if str(x) == 'nan':\n",
    "                return '0'\n",
    "            else:\n",
    "                return str(x)\n",
    "            \n",
    "        global drop2\n",
    "        def drop2(text, tr):\n",
    "            if text in tr: return ''\n",
    "            return text\n",
    "\n",
    "        \n",
    "        global mynewpreprocessing_opt\n",
    "        def mynewpreprocessing_opt(string_opt):\n",
    "            global _names, _surnames, _secondnames, df\n",
    "            \n",
    "            if string_opt != '':\n",
    "                if string_opt.count('<') == 0: \n",
    "                    return string_opt\n",
    "                if string_opt.count('<') != 0:\n",
    "#                    print (string_opt)\n",
    "                    doc = xmltodict.parse(string_opt)\n",
    "                    wk = []\n",
    "                    df = pd.DataFrame({'num': ['0']})\n",
    "                    devide_keys_values_3(wk, doc)        \n",
    "                    mtr = df.copy()        \n",
    "                    mtr.fillna('',inplace=True)        \n",
    "                    del mtr['num']  \n",
    "                    mtr = mtr.reset_index(drop=True)        \n",
    "                    nmsval = []\n",
    "                    for i in mtr.columns:\n",
    "                        if len(i) > 10:\n",
    "                            if i[-10:] == 'text-#text' or i[-25:] == 'form-select-option-@label' or i[-24:] == 'form-checkbox-@sbcommand' or i[-18:] == 'form-select-@label':\n",
    "                                nmsval.append(i)        \n",
    "                    mtrval = mtr[nmsval].copy()\n",
    "                    mtrval = [x for x in mtrval.iloc[0,:]]\n",
    "                    # почистил матрицу с текстовыми колонками от лишних символов\n",
    "                    delete = ['div', 'style', 'color', 'red', 'strong']\n",
    "                    for j in range(len(mtrval)):\n",
    "                        mtrval[j] = preptext_en(change_nan(mtrval[j]))\n",
    "                        for i in range(len(delete)):\n",
    "                            if str(mtrval[j]).count(delete[i]) > 0:\n",
    "                                mtrval[j] = ''\n",
    "                    mtrval = [x for x in mtrval if x != '']\n",
    "#                    for j in tqdm(mtrval.columns):\n",
    "#                        u = [x for x in mtrval[j].unique()]\n",
    "#                        c = [len(mtrval.loc[mtrval[j] == x, j]) for x in u]\n",
    "#                        r = [u[x] for x in range(len(c)) if c[x] > 2]\n",
    "#                        for i in range(len(mtrval[j])):\n",
    "#                            for x in range(len(r)):\n",
    "#                                if mtrval.loc[i, j] == r[x]:\n",
    "#                                    mtrval.loc[i, j] = ''\n",
    "                    vec = []\n",
    "                    for j in range(len(mtrval)):\n",
    "                        vector = [find_name_surname(mtrval[j].split())]\n",
    "                        d0 = [ vector[x] for x in range(len(vector)) if vector[x][1] != -1]\n",
    "                        vec = vec + d0\n",
    "                        \n",
    "                    self._names = list(set(self._names)); self._names.sort()\n",
    "                    self._surnames = list(set(self._surnames)); self._surnames.sort()\n",
    "                    self._secondnames = list(set(self._secondnames)); self._secondnames.sort()\n",
    "                    _trash = self._surnames + self._names + self._secondnames\n",
    "                    \n",
    "                    # удалю все фамилии и треш из полей OPTIONS\n",
    "                    for k in range(len(mtrval)):\n",
    "                        row = mtrval[k].split()\n",
    "                        vec = [drop2(j, _trash) for j in row ]\n",
    "                        vec = text_proc_3(concat(vec))\n",
    "                        mtrval[k] = collapse_ne_2(vec)       \n",
    "                    rez = ''\n",
    "                    for k in range(len(mtrval)):\n",
    "                        rez = rez + ' ' + mtrval[k]  \n",
    "                    rez = text_proc_3(rez)\n",
    "                    return rez    \n",
    "            return string_opt\n",
    "\n",
    "        global mynewpreprocessing_opt_mega\n",
    "        def mynewpreprocessing_opt_mega(string_opt):\n",
    "            global _names, _surnames, _secondnames, df\n",
    "            \n",
    "            if string_opt != '':\n",
    "                if string_opt.count('<') == 0: \n",
    "                    return string_opt\n",
    "                if string_opt.count('<') != 0:\n",
    "#                    print (string_opt)\n",
    "                    doc = xmltodict.parse(string_opt)\n",
    "                    wk = []\n",
    "                    df = pd.DataFrame({'num': ['0']})\n",
    "                    devide_keys_values_3(wk, doc)        \n",
    "                    mtr = df.copy()        \n",
    "                    mtr.fillna('',inplace=True)        \n",
    "                    del mtr['num']  \n",
    "                    mtr = mtr.reset_index(drop=True)        \n",
    "                    nmsval = []\n",
    "                    for i in mtr.columns:\n",
    "                        if len(i) > 10:\n",
    "                            if i[-10:] == 'text-#text' or i[-25:] == 'form-select-option-@label' or i[-24:] == 'form-checkbox-@sbcommand' or i[-18:] == 'form-select-@label':\n",
    "                                nmsval.append(i)        \n",
    "                    mtrval = mtr[nmsval].copy()\n",
    "                    mtrval = [x for x in mtrval.iloc[0,:]]\n",
    "                    # почистил матрицу с текстовыми колонками от лишних символов\n",
    "                    delete = ['div', 'style', 'color', 'red', 'strong']\n",
    "                    for j in range(len(mtrval)):\n",
    "                        mtrval[j] = preptext_en(change_nan(mtrval[j]))\n",
    "                        for i in range(len(delete)):\n",
    "                            if str(mtrval[j]).count(delete[i]) > 0:\n",
    "                                mtrval[j] = ''\n",
    "                    mtrval = [x for x in mtrval if x != '']\n",
    "                    for j in tqdm(mtrval.columns):\n",
    "                        u = [x for x in mtrval[j].unique()]\n",
    "                        c = [len(mtrval.loc[mtrval[j] == x, j]) for x in u]\n",
    "                        r = [u[x] for x in range(len(c)) if c[x] > 2]\n",
    "                        for i in range(len(mtrval[j])):\n",
    "                            for x in range(len(r)):\n",
    "                                if mtrval.loc[i, j] == r[x]:\n",
    "                                    mtrval.loc[i, j] = ''\n",
    "                    vec = []\n",
    "                    for j in range(len(mtrval)):\n",
    "                        vector = [find_name_surname(mtrval[j].split())]\n",
    "                        d0 = [ vector[x] for x in range(len(vector)) if vector[x][1] != -1]\n",
    "                        vec = vec + d0\n",
    "                        \n",
    "                    self._names = list(set(self._names)); self._names.sort()\n",
    "                    self._surnames = list(set(self._surnames)); self._surnames.sort()\n",
    "                    self._secondnames = list(set(self._secondnames)); self._secondnames.sort()\n",
    "                    _trash = self._surnames + self._names + self._secondnames\n",
    "                    \n",
    "                    # удалю все фамилии и треш из полей OPTIONS\n",
    "                    for k in range(len(mtrval)):\n",
    "                        row = mtrval[k].split()\n",
    "                        vec = [drop2(j, _trash) for j in row ]\n",
    "                        vec = text_proc_3(concat(vec))\n",
    "                        mtrval[k] = collapse_ne_2(vec)       \n",
    "                    rez = ''\n",
    "                    for k in range(len(mtrval)):\n",
    "                        rez = rez + ' ' + mtrval[k]  \n",
    "                    rez = text_proc_3(rez)\n",
    "                    return rez    \n",
    "            return string_opt\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        global string_replace_xml\n",
    "        def string_replace_xml(string):    \n",
    "            s1 = string.replace('&lt___div', ' ')\n",
    "            s1 = s1.replace('&#xD___', ' ')\n",
    "            s1 = s1.replace('&quot___', ' ')\n",
    "            s1 = s1.replace('&#**___', ' ')\n",
    "            s1 = s1.replace('&lt___', ' ')\n",
    "            s1 = s1.replace('&gt___', ' ')\n",
    "            s1 = s1.replace('&#', ' ')\n",
    "            s1 = s1.replace('*', ' ')\n",
    "            s1 = s1.replace('#', ' ')\n",
    "            s1 = s1.replace('.', ' ')\n",
    "            s1 = s1.replace(',', ' ')\n",
    "            s1 = s1.replace('!', ' ')\n",
    "            s1 = s1.replace('$', ' ')\n",
    "            s1 = s1.replace('%', ' ')\n",
    "            return s1\n",
    "                \n",
    "        \n",
    "        global mynewpreprocessing_opt_series\n",
    "        def mynewpreprocessing_opt_series(list_opt):\n",
    "            global _names, _surnames, _secondnames, df\n",
    "            doc = xmltodict.parse(list_opt[0])\n",
    "            wk = []\n",
    "            df = pd.DataFrame({'num': ['0']})\n",
    "            devide_keys_values_3(wk, doc)\n",
    "            mtr = df.copy()\n",
    "            for j in tqdm(range(1, len(list_opt))):\n",
    "                p = list_opt[j]\n",
    "                if str(p) != 'nan' and str(p) != '':\n",
    "                    s1 = string_replace_xml(p)\n",
    "                    doc = xmltodict.parse(s1)\n",
    "                    wk = []\n",
    "                    df = pd.DataFrame({'num': ['0']})\n",
    "                    devide_keys_values_3(wk, doc)        \n",
    "                    for i in range(df.shape[1]): mtr.loc[j,df.columns[i]] = df.iloc[0,i]\n",
    "                else:\n",
    "                    for i in range(df.shape[1]): mtr.loc[j,df.columns[i]] = ''\n",
    "            mtr.fillna('',inplace=True)\n",
    "            del mtr['num']  \n",
    "            mtr = mtr.reset_index(drop=True)\n",
    "            nmsval = []\n",
    "            for i in mtr.columns:\n",
    "                if len(i) > 10:\n",
    "                    if i[-10:] == 'text-#text' or i[-25:] == 'form-select-option-@label' or i[-24:] == 'form-checkbox-@sbcommand' or i[-18:] == 'form-select-@label':\n",
    "                        nmsval.append(i)\n",
    "            mtrval = mtr[nmsval].copy()\n",
    "            for j in (mtrval.columns):\n",
    "                mtrval[j] = [preptext_en(change_nan(x)) for x in mtrval[j]] \n",
    "            \n",
    "            for j in tqdm(mtrval.columns):\n",
    "                u = [x for x in mtrval[j].unique()]\n",
    "                c = [len(mtrval.loc[mtrval[j] == x, j]) for x in u]\n",
    "                r = [u[x] for x in range(len(c)) if c[x] > 2]\n",
    "                for i in range(len(mtrval[j])):\n",
    "                    for x in range(len(r)):\n",
    "                        if mtrval.loc[i, j] == r[x]:\n",
    "                            mtrval.loc[i, j] = ''\n",
    "            \n",
    "            vec = []\n",
    "            for k in tqdm(range(mtrval.shape[1])):\n",
    "                vector = [find_name_surname(x.split()) for x in mtrval.iloc[:,k]]\n",
    "                d0 = [ vector[x] for x in range(len(vector)) if vector[x][1] != -1]\n",
    "                vec = vec + d0   \n",
    "            self._names = list(set(self._names)); self._names.sort()\n",
    "            self._surnames = list(set(self._surnames)); self._surnames.sort()\n",
    "            self._secondnames = list(set(self._secondnames)); self._secondnames.sort()\n",
    "            _trash = self._surnames + self._names + self._secondnames\n",
    "            for k in tqdm(range(mtrval.shape[0])):\n",
    "                for i in (range(mtrval.shape[1])):\n",
    "                    row = mtrval.iloc[k,i].split()\n",
    "                    vec = [drop2(j, _trash) for j in row ]\n",
    "                    vec = text_proc_3(concat(vec))\n",
    "                    mtrval.iloc[k,i] = collapse_ne_2(vec)\n",
    "            mtrval['rez'] = mtrval.iloc[:,0]\n",
    "            cols = [x for x in mtrval.columns[1:-1]]\n",
    "            for nm in tqdm(cols):\n",
    "                mtrval['rez'] = mtrval['rez'] + ' ' + mtrval[nm]\n",
    "            list_opt = [text_proc_3(x) for x in mtrval['rez']]\n",
    "            return list_opt                \n",
    "\n",
    "# тут функционал )          \n",
    "        if isinstance(text, pd.Series):\n",
    "            if colname == 'options_mega': \n",
    "                if len([1 for x in text if x.count('<') != 0]) == 0: \n",
    "                    return text\n",
    "                if len([1 for x in text if x.count('<') != 0]) == len(text): \n",
    "                    return mynewpreprocessing_opt_mega(text)\n",
    "                if len([1 for x in text if x.count('<') != 0]) < len(text): \n",
    "                    ind = [x for x in range(len(text)) if text[x].count('<') != 0]\n",
    "                    text_opt = [x for x in text if x.count('<') != 0]\n",
    "                    text_opt = mynewpreprocessing_opt_mega(text_opt)\n",
    "                    for i in range(len(ind)):\n",
    "                        text[ind[i]] = text_opt[i]\n",
    "                return text\n",
    "            \n",
    "            if colname == 'options': \n",
    "                if len([1 for x in text if x.count('<') != 0]) == 0: \n",
    "                    return text\n",
    "                if len([1 for x in text if x.count('<') != 0]) == len(text): \n",
    "                    return mynewpreprocessing_opt_series(text)\n",
    "                if len([1 for x in text if x.count('<') != 0]) < len(text): \n",
    "                    ind = [x for x in range(len(text)) if text[x].count('<') != 0]\n",
    "                    text_opt = [x for x in text if x.count('<') != 0]\n",
    "                    text_opt = mynewpreprocessing_opt_series(text_opt)\n",
    "                    for i in range(len(ind)):\n",
    "                        text[ind[i]] = text_opt[i]\n",
    "                return text\n",
    "            if colname != 'options':                     \n",
    "                return mynewpreprocessing3(text, A = 3)\n",
    "        if isinstance(text, str):        \n",
    "            if colname != 'options':                     \n",
    "                return mynewpreprocessing4(text, A = 3)\n",
    "            if colname == 'options': \n",
    "                return mynewpreprocessing_opt(text)                \n",
    "        return text\n",
    "\n",
    "    def process(self, text):\n",
    "        if isinstance(text, pd.Series):\n",
    "            text = text.tolist()\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        if isinstance(text, list):\n",
    "            string = [mynewpreprocessing4(x, A = 3) for x in text]\n",
    "            return string\n",
    "        return text\n",
    "\n",
    "\n",
    "    def load(self):\n",
    "        misprints_arr = []\n",
    "\n",
    "    def dump(self):\n",
    "        misprints_arr = []\n",
    "        \n",
    "        # self._preprocess = None\n",
    "        # self._names = None\n",
    "        # self._processing_dict = None\n",
    "\n",
    "        # return self.dict_dump()\n",
    "\n",
    "class One_vs_all():\n",
    "    def __init__(self, train, y_train, regressor, vectorizer, preprocessor, random_state=42, params={}, num_boost_round=500):\n",
    "        self.train = train\n",
    "        self.y_train = y_train\n",
    "        self.random_state = random_state\n",
    "        self.params = params\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.y_dummied = ''\n",
    "        self.one_vs_all_models = {}\n",
    "\n",
    "        self.vectorizer = vectorizer\n",
    "        self.regressor = regressor\n",
    "        self.is_preprocessed = False\n",
    "        self.cv_dict = {}\n",
    "\n",
    "        self.preprocessor = preprocessor\n",
    "        self.preprocessed_data = None\n",
    "        self.processed_data = None\n",
    "\n",
    "    def set_preprocessor(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def remove_zero_rows(self, matr):\n",
    "        nonzero_row_indice, _ = matr.nonzero()\n",
    "        unique_nonzero_indice = np.unique(nonzero_row_indice)\n",
    "        return matr[unique_nonzero_indice], unique_nonzero_indice\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        data = pd.DataFrame(data)\n",
    "        if self.preprocessor is not None:\n",
    "            for colname in data.columns:\n",
    "                data[colname] = self.preprocessor.preprocess(colname, data[colname])\n",
    "        return data.apply(lambda x: ' '.join(x.apply(str).tolist()), axis=1)\n",
    "\n",
    "    def preprocess_fit(self):\n",
    "        if self.is_preprocessed:\n",
    "            return\n",
    "        self.vectorizer = self.vectorizer.fit(self.train)\n",
    "        train_tfidf = self.vectorizer.transform(self.train)\n",
    "\n",
    "        self.train_tfidf, not_zero_rows = self.remove_zero_rows(train_tfidf)\n",
    "\n",
    "        self.y_train = self.y_train.iloc[not_zero_rows]\n",
    "\n",
    "        self.y_dummied = pd.get_dummies(self.y_train)\n",
    "        for class_name in self.y_dummied.columns:\n",
    "            if self.y_dummied[class_name].sum() < 10:\n",
    "                self.y_dummied.drop(class_name, axis=1, inplace=True)\n",
    "\n",
    "        self.is_preprocessed = True\n",
    "\n",
    "    def model_fit(self):\n",
    "        for class_name in self.y_dummied.columns:\n",
    "            y_train = self.y_dummied[class_name]\n",
    "            temp_params = self.params\n",
    "            scale = len(y_train) / y_train.sum()\n",
    "            if self.regressor == xgb:\n",
    "                dtrain = xgb.DMatrix(self.train_tfidf, y_train)\n",
    "                temp_params[\"scale_pos_weight\"] = scale\n",
    "                class_model = xgb.train(temp_params, dtrain, self.num_boost_round)\n",
    "            else:\n",
    "                dtrain = self.train_tfidf\n",
    "                params = self.params\n",
    "                params['random_state'] = self.random_state\n",
    "                class_model = self.regressor(**params).fit(dtrain, y_train)\n",
    "\n",
    "            self.one_vs_all_models[class_name] = class_model\n",
    "\n",
    "    def cv_model(self):\n",
    "        if self.regressor != xgb:\n",
    "            print('cv_model supported only for xgboost')\n",
    "            return None\n",
    "\n",
    "        self.preprocess_fit()\n",
    "        if len(self.cv_dict) > 0:\n",
    "            return self.cv_dict\n",
    "\n",
    "        cv_dict = {}\n",
    "        for class_name in self.y_dummied.columns:\n",
    "            print('cv for ', class_name)\n",
    "            y_train = self.y_dummied[class_name]\n",
    "            if self.regressor == xgb:\n",
    "                dtrain = xgb.DMatrix(self.train_tfidf, y_train)\n",
    "                cv_info = xgb.cv(self.params, dtrain, num_boost_round=self.num_boost_round, nfold=5, stratified=True, metrics='logloss', verbose_eval=100)\n",
    "                '''else:\n",
    "                params = self.params\n",
    "                params['random_state'] = self.random_state\n",
    "                scoresSSS = cross_val_score(self.regressor(**params), self.train_tfidf, y_train, cv=5, n_jobs=-1)\n",
    "                cv_info = np.average(scoresSSS)\n",
    "                #print(cv_info)'''\n",
    "            cv_dict[class_name] = cv_info\n",
    "        self.cv_dict = cv_dict\n",
    "        return cv_dict\n",
    "\n",
    "    def clear(self):\n",
    "        del self.train_tfidf\n",
    "        del self.y_dummied\n",
    "\n",
    "    def mypredict_single(self, text):\n",
    "        result = {}\n",
    "        if isinstance(text, pd.Series):\n",
    "            text = text.tolist()\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        if isinstance(text, list):\n",
    "### 27_06_18 start\n",
    "            text = self.preprocessor.preprocess('DESCRIPTION', text)\n",
    "### 27_06_18 end\n",
    "            test = self.vectorizer.transform(text)\n",
    "#            y_pred = self.regressor.predict(test)\n",
    "            res = self.regressor.predict_proba(test)\n",
    "            res = pd.DataFrame(res)\n",
    "            res.columns = self.regressor.classes_\n",
    "            result['res_class'] = str(res.idxmax(axis=1).iloc[0])\n",
    "            result['res_prob'] = res.max(axis=1).iloc[0]\n",
    "            return result\n",
    "        return {'res_class': '', 'res_prob': 0.0}\n",
    "\n",
    "\n",
    "    def mypredict_double(self,text):\n",
    "        result = {}\n",
    "        desr = text[0]\n",
    "        opt = text[1] \n",
    "        desr = self.preprocessor.preprocess('DESCRIPTION', desr)\n",
    "        opt = self.preprocessor.preprocess('options', opt)\n",
    "        text = desr + ' ' + opt\n",
    "        if isinstance(text, pd.Series):\n",
    "            text = text.tolist()\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        if isinstance(text, list):\n",
    "            test = self.vectorizer.transform(text)\n",
    "#            y_pred = self.regressor.predict(test)\n",
    "            res = self.regressor.predict_proba(test)\n",
    "            res = pd.DataFrame(res)\n",
    "            res.columns = self.regressor.classes_\n",
    "            result['res_class'] = str(res.idxmax(axis=1).iloc[0])\n",
    "            result['res_prob'] = res.max(axis=1).iloc[0]\n",
    "            return result\n",
    "        return {'res_class': '', 'res_prob': 0.0}\n",
    "\n",
    " \n",
    "\n",
    "    def predict_single(self, text):\n",
    "        if self.preprocessor is not None:\n",
    "            text = self.preprocessor.process(text)\n",
    "        else:\n",
    "            text = [text]\n",
    "        print(text)\n",
    "        test = text\n",
    "        test_tfidf = self.vectorizer.transform(test)\n",
    "        if self.regressor == xgb:\n",
    "            dtest = xgb.DMatrix(test_tfidf)\n",
    "        else:\n",
    "            dtest = test_tfidf\n",
    "        result = {}\n",
    "        if type(self.regressor).__name__ in ['type', 'module']:\n",
    "            for class_name in self.one_vs_all_models:\n",
    "                model = self.one_vs_all_models[class_name]\n",
    "                proba = model.predict(dtest)[0].apply(str)\n",
    "                if proba > 0.5:\n",
    "                    result[class_name] = proba\n",
    "        else:\n",
    "            res = self.regressor.predict_proba(dtest)\n",
    "            res = pd.DataFrame(res)\n",
    "            res.columns = self.regressor.classes_\n",
    "            result['res_class'] = str(res.idxmax(axis=1).iloc[0])\n",
    "            result['res_proba'] = res.max(axis=1).iloc[0]\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict1(self, test, debug=False):\n",
    "        if isinstance(test, pd.Series):\n",
    "            test = test.tolist()\n",
    "        if isinstance(test, str) or isinstance(test, dict):\n",
    "            test = [test]\n",
    "            # return self.predict_single(test)\n",
    "\n",
    "        test = [self.preprocessor.parse(node) for node in test]\n",
    "\n",
    "        index = None\n",
    "        if isinstance(test, pd.Series):\n",
    "            index = test.index\n",
    "            result = pd.DataFrame(columns=self.one_vs_all_models.keys(), index=index)\n",
    "        else:\n",
    "            result = pd.DataFrame(columns=self.one_vs_all_models.keys())\n",
    "\n",
    "        test = self.preprocess_data(test)\n",
    "        if debug:\n",
    "            self.preprocessed_data = test\n",
    "        test = self.preprocessor.process(test)\n",
    "        if debug:\n",
    "            self.processed_data = test\n",
    "\n",
    "        test_tfidf = self.vectorizer.transform(test)\n",
    "        if self.regressor == xgb:\n",
    "            dtest = xgb.DMatrix(test_tfidf)\n",
    "\n",
    "        if type(self.regressor).__name__ in ['type', 'module']:\n",
    "            for class_name in self.one_vs_all_models:\n",
    "                model = self.one_vs_all_models[class_name]\n",
    "                if self.regressor == xgb:\n",
    "                    proba = model.predict(dtest)\n",
    "                else:\n",
    "                    proba = model.predict(test_tfidf)\n",
    "                result[class_name.apply(str)] = proba.apply(str)\n",
    "            # return {'res_class': result.idxmax(axis=1).apply(str), 'res_proba':result.apply(str)}\n",
    "            if result.shape[0] == 1:\n",
    "                return {'res_class': str(result.idxmax(axis=1).iloc[0]), 'res_proba': float(result.max(axis=1).iloc[0])}\n",
    "            else:\n",
    "                return {'res_class': result.idxmax(axis=1).apply(str), 'res_proba': result.max(axis=1).apply(float)}\n",
    "        else:\n",
    "            y_pred = self.regressor.predict_proba(test_tfidf)\n",
    "#             result = clf.predict_proba(X_full_arr)\n",
    "            result = pd.DataFrame(y_pred)\n",
    "            result.columns = self.regressor.classes_\n",
    "            if index is not None:\n",
    "                # print('apply index')\n",
    "                result.index = index\n",
    "            # print(result.idxmax(axis=1), result.max(axis=1))\n",
    "            # return result.idxmax(axis=1), result\n",
    "            if result.shape[0] == 1:\n",
    "                return {'res_class': str(result.idxmax(axis=1).iloc[0]), 'res_proba': float(result.max(axis=1).iloc[0])}\n",
    "            else:\n",
    "                return {'res_class': result.idxmax(axis=1).apply(str), 'res_proba': result.max(axis=1).apply(float)}\n",
    "\n",
    "    def set_ms(self, mystem):\n",
    "        self.preprocessor.set_ms(mystem)\n",
    "\n",
    "    def dump(self, path):\n",
    "#        self.set_ms(None)\n",
    "        preprocessed_data = self.preprocessed_data\n",
    "        self.preprocessed_data = None\n",
    "        processed_data = self.processed_data\n",
    "        self.processed_data = None\n",
    "        self.preprocessor.dump()\n",
    "        with open(path, 'wb') as model:\n",
    "            pickle.dump(self, model)\n",
    "\n",
    "    def load(path):\n",
    "        with open(path, 'rb') as model:\n",
    "            tmp_model = pickle.load(model)\n",
    "#        tmp_model.set_ms(MS)\n",
    "        tmp_model.preprocessor.load()\n",
    "        return tmp_model\n",
    "\n",
    "    def reload(self, path):\n",
    "        self = self.load(path)\n",
    "\n",
    "    def get_debug_data(self):\n",
    "        try:\n",
    "            return {'preprocessed_data': self.preprocessed_data, 'processed_data': self.processed_data}\n",
    "        except:\n",
    "            return {'preprocessed_data': None, 'processed_data': None}\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def text_proc_3(text):\n",
    "    if text != '':\n",
    "        text = re.sub(r\"\\s+\", \" \", text) # убрал лишние пробелы (\\s+ Любой пробельный символ 1 и более вхождений шаблона)\n",
    "        text = re.sub(r\"^\\s+\", \"\", text) #  уберу первые пробелы в начале строки\n",
    "        text = text.rstrip() #  уберу последний пробел в начале строки\n",
    "    return text\n",
    "\n",
    "def concat(vec):\n",
    "    return ' '.join(vec)\n",
    "\n",
    "\n",
    "def got_counter(per):\n",
    "    counter = Counter()\n",
    "    for i in range(len(per)):\n",
    "        word = per[i]\n",
    "        counter[word] += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/ML/vIFO/datas/'\n",
    "SS = 'way4_05'\n",
    "\n",
    "data_all = pd.read_csv(path + SS + '.csv', sep=';', encoding = 'cp1251')\n",
    "data_all.fillna('',inplace=True)\n",
    "\n",
    "data_all = data_all[['OPEN_TIME', 'NUMBER', 'AFFECTED_ITEM_NAME', 'ASSIGNEE_NAME',\n",
    "       'ASSIGNMENT_NAME', 'TITLE', 'PROTOCOL', 'DESCRIPTION', 'RESOLUTION', 'OPTIONS', 'Class']]\n",
    "\n",
    "counter = got_counter(data_all['AFFECTED_ITEM_NAME'])\n",
    "res_df = pd.DataFrame.from_dict(counter, orient='index').reset_index().rename(columns={'index':'event', 0:'count'})\n",
    "res_df = res_df.sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#                                                event  count\n",
    "#0   Way4 - Процессинг банковских карт (CI00058876)   4222\n",
    "#1   Smart Vista - Фронтальная система терминальных...   2232\n",
    "#2   Информационно-поисковая система для банковских...    865\n",
    "#3   Система мониторинга сети банкоматов (СМСБ) ЦА,...    792\n",
    "#4   Сверка операций на устройствах самообслуживани...    226\n",
    "#5   Платформа автоматизации развития устройств сам...    156\n",
    "#6   Smart Vista Fraud Prevention (CI00163953)    112\n",
    "#7   Управление безопасностью ИТ-услуг (CI00306371)     99\n",
    "#8                                                   81\n",
    "#9   Формирование отчетности для клиентов банка (Вы...     40\n",
    "#10  ФЛ.02_Расчеты по банковским картам и устройств...     19\n",
    "\n",
    "\n",
    "data_all = data_all[data_all['Class'] != '' ].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "Name = pd.read_csv(path+'dict/mynames2.csv', sep=';', encoding = 'cp1251')\n",
    "Name = [x for x in Name.iloc[:,0]]; Name = list(set(Name)); Name.sort()\n",
    "Surname = pd.read_csv(path+'dict/mysurnames2.csv', sep=';', encoding = 'cp1251')\n",
    "Surname = [x for x in Surname.iloc[:,0]]; Surname = list(set(Surname)); Surname.sort()\n",
    "Secondname = pd.read_csv(path+'dict/mysecondnames2.csv', sep=';', encoding = 'cp1251')\n",
    "Secondname = [x for x in Secondname.iloc[:,0]]; Secondname = list(set(Secondname)); Secondname.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = myPreprocessor(_names= [Name, Surname, Secondname])\n",
    "\n",
    "\n",
    "data_all.columns\n",
    "data_all['DESCRIPTION_'] = preprocessor.preprocess('DESCRIPTION', data_all['DESCRIPTION'])\n",
    "data_all['OPTIONS_'] = preprocessor.preprocess('options', data_all['OPTIONS'])\n",
    "data_all['RESOLUTION_'] = preprocessor.preprocess('DESCRIPTION', data_all['RESOLUTION'])\n",
    "\n",
    "feat = ['DESCRIPTION_', 'OPTIONS_', 'RESOLUTION_']\n",
    "S = 'process'\n",
    "data_all[S] = [text_proc_3(concat([z for z in data_all.loc[x, feat]])) for x in tqdm(range(len(data_all[feat])))]     \n",
    "data_all['NUMBER'] = data_all['NUMBER'].apply(lambda x: x.strip())\n",
    "data_all['process'] = data_all['process'].apply(lambda x: x.strip())\n",
    "data_all['Class'] = data_all['Class'].apply(lambda x: x.strip())\n",
    "data_all = data_all[data_all['Class'] != ''].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мешок слов и модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = data_all['process']\n",
    "y_full = data_all['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full,train_size=0.80, random_state=1, stratify = y_full)\n",
    "\n",
    "X_train_c = X_train.copy()\n",
    "X_test_c = X_test.copy() \n",
    "y_train_c  = [x for x in y_train]\n",
    "y_test_c = [x for x in y_test]\n",
    "\n",
    "vectorizer=TfidfVectorizer(analyzer='word', lowercase=False, ngram_range=(1, 3), min_df=0.0005, max_df=0.995, max_features = None)\n",
    "X_full = vectorizer.fit_transform(X_full)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "print(\"Количество признаков {}\".format(X_train.shape[1]))\n",
    "\n",
    "class_names = sorted(np.unique(y_full))\n",
    "weights = [1 for i in range(0,len(class_names))]\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    weights[i] = len(y_full[y_full == class_names[i]])*100.0/len(y_full)\n",
    "\n",
    "class_weight=dict(zip(class_names, weights))\n",
    "class_weight\n",
    "\n",
    "\n",
    "name = 'Logistic Regression'\n",
    "clf_default = LogisticRegression(random_state=random_state, n_jobs=-1)\n",
    "params = {'penalty' : ['l2'],\n",
    "          'tol': [1e-2,1e-1],\n",
    "          'C': [x for x in range(10, 21, 2)],\n",
    "          'fit_intercept': (True, False),\n",
    "          'class_weight': ['balanced', None, class_weight],\n",
    "          'multi_class' : ['ovr'],\n",
    "          'solver': ['sag'],\n",
    "          'max_iter' : (5,7,9,11,15,21)\n",
    "           }\n",
    "\n",
    "start_time = datetime.datetime.now() \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "clf = GridSearchCV(clf_default, params, cv=skf, n_jobs=-1, verbose = 10, error_score = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(datetime.datetime.now() - start_time)\n",
    "best_clf = clf.best_estimator_\n",
    "print(clf.best_score_)\n",
    "print(best_clf)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "cv_score = cross_val_score(best_clf, X_train, y_train, cv = skf, n_jobs=-1)\n",
    "print('cv_score.mean', cv_score.mean())\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print ( 'Accuracy test', accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "np.set_printoptions(precision=2)\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix test')\n",
    "fig.savefig('lr_test1.jpg')\n",
    "\n",
    "y_pred = best_clf.predict(X_full)\n",
    "data_all['Class1'] = y_pred\n",
    "mistake = [compare(data_all['Class'][x], data_all['Class1'][x]) for x in range(len(data_all))]\n",
    "print(np.sum(mistake)/len(mistake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "vct = pd.Series([x for x in y_test])\n",
    "d = custom_confusion_matrix(vct, y_pred)\n",
    "cm = confusion_matrix(vct, y_pred)\n",
    "FP = cm.sum(axis=0) - np.diag(cm)\n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "TPR = TP*1.0/(TP+FN); TNR = TN*1.0/(TN+FP) \n",
    "PPV = TP*1.0/(TP+FP); NPV = TN*1.0/(TN+FN)\n",
    "FPR = FP*1.0/(FP+TN); FNR = FN*1.0/(TP+FN)\n",
    "FDR = FP*1.0/(TP+FP); ACC = (TP+TN)*1.0/(TP+FP+FN+TN)\n",
    "\n",
    "columns = ['class', 'count', 'TP', 'FP', 'FN', 'TN', 'Полнота', 'TNR', 'precision', 'NPV', 'FPR', 'FNR', 'FDR', 'ACC']\n",
    "matrix = pd.DataFrame( np.zeros( (len(vct.value_counts()),14) , dtype = float), columns = columns)\n",
    "matrix['class'] = [x for x in d.index[:-1]]\n",
    "matrix['count'] = [len(vct[vct == cls]) for cls in [x for x in d.index[:-1]] ]\n",
    "matrix['TP'] = TP; matrix['FP'] = FP\n",
    "matrix['TN'] = TN; matrix['FN'] = FN\n",
    "matrix['Полнота'] = TPR; \n",
    "matrix['TNR'] = TNR\n",
    "matrix['Точность'] = PPV; \n",
    "matrix['NPV'] = NPV\n",
    "matrix['FPR'] = FPR; matrix['FNR'] = FNR\n",
    "matrix['FDR'] = FDR; matrix['ACC'] = ACC\n",
    "\n",
    "matrix.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
