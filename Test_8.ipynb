{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании будет использоваться датасет digits из sklearn.datasets. \n",
    "Оставьте последние 25% объектов для контроля качества, \n",
    "разделив X и y на X_train, y_train и X_test, y_test.\n",
    "Целью задания будет реализовать самый простой метрический классификатор — метод ближайшего соседа,\n",
    "а также сравнить качество работы реализованного вами 1NN с RandomForestClassifier из sklearn на 1000 деревьях.\n",
    "\n",
    "Задание 1\n",
    "\n",
    "Реализуйте самостоятельно метод одного ближайшего соседа с евклидовой метрикой для задачи классификации. \n",
    "Ваша реализация может быть устроена следующим образом: можно для каждого классифицируемого объекта \n",
    "составлять список пар (расстояние до точки из обучающей выборки, метка класса в этой точке), \n",
    "затем сортировать этот список (по умолчанию сортировка будет сначала по первому элементу пары, \n",
    "затем по второму), а затем брать первый элемент (с наименьшим расстоянием).\n",
    "Сортировка массива длиной N требует порядка N log N сравнений (строже говоря, она работает за O(N log N)). \n",
    "Подумайте, как можно легко улучшить получившееся время работы. \n",
    "Кроме простого способа найти ближайший объект всего за N сравнений, можно попробовать придумать, \n",
    "как разбить пространство признаков на части и сделать структуру данных, \n",
    "которая позволит быстро искать соседей каждой точки. \n",
    "За выбор метода поиска ближайших соседей в KNeighborsClassifier \n",
    "из sklearn отвечает параметр algorithm — если у вас уже есть некоторый бэкграунд в алгоритмах и структурах данных,\n",
    "вам может быть интересно познакомиться со структурами данных ball tree и kd tree.\n",
    "Доля ошибок, допускаемых 1NN на тестовой выборке, — ответ в задании 1.\n",
    "\n",
    "\n",
    "Задание 2\n",
    "\n",
    "Теперь обучите на обучающей выборке RandomForestClassifier(n_estimators=1000) из sklearn. \n",
    "Сделайте прогнозы на тестовой выборке и оцените долю ошибок классификации на ней. \n",
    "Эта доля — ответ в задании 2. \n",
    "Обратите внимание на то, как соотносится качество работы случайного леса с качеством работы, \n",
    "пожалуй, одного из самых простых методов — 1NN. Такое различие — особенность данного датасета, \n",
    "но нужно всегда помнить, что такая ситуация тоже может иметь место, и не забывать про простые методы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Classifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "    def scale(self, X):\n",
    "        X = self.scaler.fit_transform(X)\n",
    "        return X\n",
    "\n",
    "    def add_class(self, X_train, y_train):\n",
    "        X_train2 = np.zeros((X_train.shape[0], X_train.shape[1]+1), dtype = float)\n",
    "        X_train2[:, :-1] = X_train[:,:].copy()    \n",
    "        X_train2[:, -1] = y_train\n",
    "        return X_train2\n",
    "    \n",
    "    @staticmethod    \n",
    "    def euclideanDistance(instance1, instance2):\n",
    "        distance = 0\n",
    "        length = len(instance1) - 1\n",
    "        for x in range(length):\n",
    "            distance += pow((instance1[x] - instance2[x]), 2)\n",
    "        return sqrt(distance)\n",
    "    \n",
    "    def euclidean_distance(self, row1, row2):\n",
    "        distance = 0.0\n",
    "        for i in range(len(row1)-1):\n",
    "            distance += (row1[i] - row2[i])**2\n",
    "        return sqrt(distance)\n",
    "    \n",
    "    def get_neighbors(self, train, test_row, k):\n",
    "        distances = []\n",
    "        for train_row in train:\n",
    "            dist = self.euclidean_distance(test_row, train_row)\n",
    "            distances.append([train_row, dist])\n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        neighbors = []\n",
    "        for i in range(k):\n",
    "            neighbors.append(distances[i][0])\n",
    "        return neighbors\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_neighbors1(train, test_row, k):\n",
    "        distances = []\n",
    "        dst = []\n",
    "        mn = 10000\n",
    "        for train_row in train:\n",
    "            dist = KNN_Classifier.euclideanDistance(test_row, train_row)\n",
    "            distances.append([train_row, dist])\n",
    "            dst.append(dist)\n",
    "            if dist < mn:\n",
    "                mn = dist\n",
    "        if k == 1:\n",
    "            neighbors = [distances[dst.index(mn)]]\n",
    "        else:\n",
    "            distances.sort(key=lambda x: x[1])\n",
    "            neighbors = []\n",
    "            for i in range(k):\n",
    "                neighbors.append(distances[i][0])\n",
    "        return neighbors\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_neighborsK(train, test_row, k):\n",
    "        dst = []\n",
    "        mn = [10000 for x in range(k)]\n",
    "        for train_row in train:\n",
    "            dist = KNN_Classifier.euclideanDistance(test_row, train_row)\n",
    "            dst.append(dist)\n",
    "            mn.append(dist)\n",
    "            mn.sort()\n",
    "            mn = mn[:k]\n",
    "        mn.sort()\n",
    "        if k == 1:\n",
    "            neighbors = [train[dst.index(mn[0])]]\n",
    "        else:\n",
    "            neighbors = []\n",
    "            for i in range(k):\n",
    "                neighbors.append(train[dst.index(mn[i])])\n",
    "        return neighbors\n",
    "    \n",
    "    def find_center_clasters(self, X_train2):\n",
    "        centers = []\n",
    "        y = X_train2[:,-1]\n",
    "        y = list(set(y))\n",
    "        y.sort()\n",
    "        for i in range(len(y)):\n",
    "            xc = X_train2[X_train2[:,-1] == y[i]][:-1]\n",
    "            v = [np.mean(xc[:,x]) for x in range(xc.shape[1])]+[y[i]]\n",
    "            centers.append(v)\n",
    "        return centers \n",
    "    \n",
    "    def find_center_clasters2(self, X_train2):\n",
    "        centers = []\n",
    "        y = X_train2[:,-1]\n",
    "        y = list(set(y))\n",
    "        y.sort()\n",
    "        for i in range(len(y)):\n",
    "            xc = X_train2[X_train2[:,-1] == y[i]][:-1]\n",
    "            v = [np.median(xc[:,x]) for x in range(xc.shape[1])]+[y[i]]\n",
    "            centers.append(v)\n",
    "            v = [np.mean(xc[:,x]) for x in range(xc.shape[1])]+[y[i]]\n",
    "            centers.append(v)\n",
    "            v = [stats.mode(xc[:,0])[0][0] for x in range(xc.shape[1])]+[y[i]]\n",
    "            centers.append(v)  \n",
    "        return centers \n",
    "    \n",
    "    def predict_knn(self, train, test_row, k):\n",
    "        neighbors = self.get_neighbors(train, test_row, k)\n",
    "        output_values = [row[-1] for row in neighbors]\n",
    "        unique, counts = np.unique(output_values, return_counts=True)\n",
    "        counter = dict(zip(unique, counts))\n",
    "        res_df = pd.DataFrame.from_dict(counter, orient='index').reset_index().rename(columns={'index':'event', 0:'count'})\n",
    "        res_df = res_df.sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "        prediction = res_df.iloc[0,0]\n",
    "        return prediction\n",
    "    \n",
    "    def predict_knn2(self, train, test_row, k):\n",
    "        centers = self.find_center_clasters(train)\n",
    "        neighbors = self.get_neighbors(centers, test_row, k)\n",
    "        output_values = [row[-1] for row in neighbors]\n",
    "        unique, counts = np.unique(output_values, return_counts=True)\n",
    "        counter = dict(zip(unique, counts))\n",
    "        res_df = pd.DataFrame.from_dict(counter, orient='index').reset_index().rename(columns={'index':'event', 0:'count'})\n",
    "        res_df = res_df.sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "        prediction = res_df.iloc[0,0]\n",
    "        return prediction\n",
    "    \n",
    "    def predict_knn3(self, train, test_row, k):\n",
    "        centers = self.find_center_clasters2(train)\n",
    "        neighbors = self.get_neighbors(centers, test_row, k)\n",
    "        output_values = [row[-1] for row in neighbors]\n",
    "        unique, counts = np.unique(output_values, return_counts=True)\n",
    "        counter = dict(zip(unique, counts))\n",
    "        res_df = pd.DataFrame.from_dict(counter, orient='index').reset_index().rename(columns={'index':'event', 0:'count'})\n",
    "        res_df = res_df.sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "        prediction = res_df.iloc[0,0]\n",
    "        return prediction\n",
    "    \n",
    "    def accuracy_metric(self, actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return round(correct / float(len(actual)) * 100.0, 2)\n",
    "     \n",
    "    def getAccuracy(self, testSet, predictions):\n",
    "        correct = 0\n",
    "        for x in range(len(testSet)):\n",
    "            if testSet[x][-1] == predictions[x]:\n",
    "                correct += 1\n",
    "        return round((correct/float(len(testSet))) * 100.0, 2)\n",
    " \n",
    "    def test1(self, X_train2, X_test2, k): \n",
    "        predictions=[]\n",
    "        for i in tqdm(range(len(X_test2))):\n",
    "            result = self.predict_knn(X_train2, X_test2[i], k)\n",
    "            predictions.append(result)\n",
    "        accuracy = self.getAccuracy(X_test2, predictions)\n",
    "        print('Accuracy1: ' + repr(accuracy) + '%')\n",
    "        accuracy = self.accuracy_metric(y_test, predictions)\n",
    "        print('Accuracy2: ' + repr(accuracy) + '%')\n",
    "\n",
    "    def test2(self, X_train2, X_test2, k): \n",
    "        predictions=[]\n",
    "        for i in tqdm(range(len(X_test2))):\n",
    "            result = self.predict_knn2(X_train2, X_test2[i], k)\n",
    "            predictions.append(result)\n",
    "        accuracy = self.getAccuracy(X_test2, predictions)\n",
    "        print('Accuracy1: ' + repr(accuracy) + '%')\n",
    "        accuracy = self.accuracy_metric(y_test, predictions)\n",
    "        print('Accuracy2: ' + repr(accuracy) + '%')\n",
    "\n",
    "    def test3(self, X_train2, X_test2, k): \n",
    "        predictions=[]\n",
    "        for i in tqdm(range(len(X_test2))):\n",
    "            result = self.predict_knn3(X_train2, X_test2[i], k)\n",
    "            predictions.append(result)\n",
    "        accuracy = self.getAccuracy(X_test2, predictions)\n",
    "        print('Accuracy1: ' + repr(accuracy) + '%')\n",
    "        accuracy = self.accuracy_metric(y_test, predictions)\n",
    "        print('Accuracy2: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создать экземпляр класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnc = KNN_Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = knnc.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбить на данные для обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавить класс в выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = knnc.add_class(X_train, y_train)\n",
    "X_test2 = knnc.add_class(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная реализация метода одного ближайшего соседа с евклидовой метрикой для задачи классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [00:27<00:00, 16.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy1: 98.44%\n",
      "Accuracy2: 98.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knnc.test1(X_train2, X_test2, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответ 1: 98.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Придумать, как разбить пространство признаков на части и сделать структуру данных, которая позволит быстро искать соседей каждой точки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Найду центры каждого кластера как среднее по каждой фиче и буду сравнивать с ними"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [00:03<00:00, 148.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy1: 87.56%\n",
      "Accuracy2: 87.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knnc.test2(X_train2, X_test2, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Найду центры каждого кластера как (среднее, медиана, мода) по каждой фиче и буду сравнивать с ними"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [00:34<00:00, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy1: 87.56%\n",
      "Accuracy2: 87.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knnc.test3(X_train2, X_test2, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество уменьшилось, но скорость поиска намного выросла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартный поиск ближайшего соседа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.9 ms, sys: 1.1 ms, total: 64 ms\n",
      "Wall time: 63.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neighbors = knnc.get_neighbors(X_train, X_train[0], k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Различные тесты ускорения поиска ближайшего соседа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.3 ms, sys: 1.51 ms, total: 67.8 ms\n",
      "Wall time: 66.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neighbors = KNN_Classifier.get_neighbors1(X_train, X_train[0], k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65 ms, sys: 1.51 ms, total: 66.5 ms\n",
      "Wall time: 65.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neighbors = KNN_Classifier.get_neighborsK(X_train, X_train[0], k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy1: 97.11%\n",
      "Accuracy2: 97.11%\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "accuracy = knnc.getAccuracy(X_test2, y_pred)\n",
    "print('Accuracy1: ' + repr(accuracy) + '%')\n",
    "accuracy = knnc.accuracy_metric(y_test, y_pred)\n",
    "print('Accuracy2: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответ 2: 97.11%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Случайный лес показал худжий результат, чем базовый алгоритм поиска ближайшего соседа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
